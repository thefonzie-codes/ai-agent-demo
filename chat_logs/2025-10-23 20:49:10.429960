ðŸ§‘ User: how many issues
ðŸ¤– Agent: sdk_http_response=HttpResponse(
  headers=<dict len=10>
) candidates=[Candidate(
  content=Content(
    parts=[
      Part(
        function_call=FunctionCall(
          args={
            'sqlite3_query': 'SELECT count(*) FROM issues'
          },
          name='search_db'
        ),
        thought_signature=b'\n\xe6\x01\x01\xd1\xed\x8ao\x92P\xff\x16 \x9cp#\xa8\x9b\x9f\xaa\xc9\xac!\x05\xab\x16\x86<\xaf{\x01\x9e\x04\xac\xcd`\xe52\x90_\xe6\xb6\xa9(\x8d@1_~\xffE\xe66\xab#\xc6\nt\xff\xcf\x93\xb78\x97|\xfc\xf6\xae\xd1p\xa7\x1a\xb18n\x08*6\xaar\xc4\x19\xa8D\x1fC\xd3\t\x0e\x80\xf6lK\xda\xb7\x1a\xea...'
      ),
    ],
    role='model'
  ),
  finish_reason=<FinishReason.STOP: 'STOP'>,
  index=0
)] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='hpT6aK_xDsGJ-sAPwfWn-Q0' usage_metadata=GenerateContentResponseUsageMetadata(
  candidates_token_count=22,
  prompt_token_count=77,
  prompt_tokens_details=[
    ModalityTokenCount(
      modality=<MediaModality.TEXT: 'TEXT'>,
      token_count=77
    ),
  ],
  thoughts_token_count=52,
  total_token_count=151
) automatic_function_calling_history=[] parsed=None
ðŸ§‘ User: were you able to find the answer?
ðŸ¤– Agent: sdk_http_response=HttpResponse(
  headers=<dict len=10>
) candidates=[Candidate(
  content=Content(
    parts=[
      Part(
        text='I do not have the answer yet, please provide the results of the `search_db` call.',
        thought_signature=b'\n\xa0\x06\x01\xd1\xed\x8ao#\x9b\xc2\xaa\x83\xe6\x9ec\xb7\x9b\xe8\xf2\xd4w\xfd\x98\xef<\xead;\xcd$vn\xa5\xe5+\xbd\xf6\x99\xfbS[\xe5\xf7\xc1\xfa\xa0\xbd\x8eM\xc6>\x1d\xfd\xa5\xe4o\x8a\xf8\xfc\xb3\xf9\xe3\xeb\xbd\xce\xd6\x01\x92\xda\xf0\x11.\xcfV\x15\x9c\x8b\x07\x97\x11\x05\xa5\xde\xf1\xb1\xd5\xc4nf\x0c\xed/\xf0}\xb2\xd1...'
      ),
    ],
    role='model'
  ),
  finish_reason=<FinishReason.STOP: 'STOP'>,
  index=0
)] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='qZT6aKT9MYKrjMcP6paM6Q4' usage_metadata=GenerateContentResponseUsageMetadata(
  candidates_token_count=21,
  prompt_token_count=614,
  prompt_tokens_details=[
    ModalityTokenCount(
      modality=<MediaModality.TEXT: 'TEXT'>,
      token_count=614
    ),
  ],
  thoughts_token_count=178,
  total_token_count=813
) automatic_function_calling_history=[] parsed=None
ðŸ§‘ User: exit
ðŸ¤– Agent: sdk_http_response=HttpResponse(
  headers=<dict len=10>
) candidates=[Candidate(
  content=Content(
    parts=[
      Part(
        text='Thank you, goodbye!',
        thought_signature=b'\n\x7f\x01\xd1\xed\x8ao\x05\xc4\xe0\xac;\xf3\x18\xaa\xe2M\xdej\xeeH\xfc\x17\xe1\xb7P5\xe5g8\xb6\xe5\xe5yN\xe3\x1c\xf9%A\xe1\x90\x95\x1a\xe0t\xa9\xf6\x92\xa1\x9a\xa7\xf2\xd1\xc7!5\x0e\xc0g\xd7\xafZ\xe0\x93\xa8fG\x1d\x9b5\xb0\xfd\x1e\xf9\xb0\xd87\x19\xee<1\xc9\x1exq%I`\xa7`\x0c~\xec@J\xae...'
      ),
    ],
    role='model'
  ),
  finish_reason=<FinishReason.STOP: 'STOP'>,
  index=0
)] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='xpT6aNPqFJfdjMcP7cXAOQ' usage_metadata=GenerateContentResponseUsageMetadata(
  candidates_token_count=5,
  prompt_token_count=1139,
  prompt_tokens_details=[
    ModalityTokenCount(
      modality=<MediaModality.TEXT: 'TEXT'>,
      token_count=1139
    ),
  ],
  thoughts_token_count=20,
  total_token_count=1164
) automatic_function_calling_history=[] parsed=None
